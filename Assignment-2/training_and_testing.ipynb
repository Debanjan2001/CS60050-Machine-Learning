{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:07.364427Z",
     "start_time": "2021-10-18T16:44:07.079427Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:08.122837Z",
     "start_time": "2021-10-18T16:44:07.365977Z"
    }
   },
   "outputs": [],
   "source": [
    "featureMatrix = sp.load_npz(\"feature_matrix.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:08.149602Z",
     "start_time": "2021-10-18T16:44:08.125738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19579x24951 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 250731 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:08.561129Z",
     "start_time": "2021-10-18T16:44:08.151287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  453,  1286,  1636,  3702,  6102,  6862,  8189, 10730, 13337,\n",
       "        13640, 13875, 16003, 16564, 17069, 18513, 19478, 19625, 23225,\n",
       "        24168, 24416, 24641]),)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing if generated matrix was okay or not\n",
    "np.where(featureMatrix.toarray()[0] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T17:02:12.155866Z",
     "start_time": "2021-10-12T17:02:11.908703Z"
    }
   },
   "source": [
    "#### The code above was a test to check if everything seems fine after loading the featureMatrix from disk. Looks good to me\n",
    "\n",
    "### TRAINING: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:08.618941Z",
     "start_time": "2021-10-18T16:44:08.562834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:08.826988Z",
     "start_time": "2021-10-18T16:44:08.620862Z"
    }
   },
   "outputs": [],
   "source": [
    "num_examples, num_vocab_words = featureMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:09.220879Z",
     "start_time": "2021-10-18T16:44:08.828417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EAP', 'HPL', 'MWS']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = list(train_df[\"author\"].unique())\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:09.279871Z",
     "start_time": "2021-10-18T16:44:09.231472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EAP': 0, 'HPL': 1, 'MWS': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelMap = {}\n",
    "for idx, label in enumerate(class_labels):\n",
    "    labelMap[label] = idx\n",
    "labelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:09.347109Z",
     "start_time": "2021-10-18T16:44:09.281852Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split_indices(num_examples, percentage_split):\n",
    "    all_indices = [i for i in range(num_examples)]\n",
    "    random.shuffle(all_indices)\n",
    "    num_training_examples = int(num_examples * percentage_split / 100 )\n",
    "    num_test_examples = num_examples - num_training_examples\n",
    "    train_indices, test_indices = all_indices[:num_training_examples], all_indices[num_training_examples:]\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:09.417984Z",
     "start_time": "2021-10-18T16:44:09.348953Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:09.509395Z",
     "start_time": "2021-10-18T16:44:09.424268Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"word_index.json\", \"r\") as file:\n",
    "    wordIndex = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:44:09.604656Z",
     "start_time": "2021-10-18T16:44:09.511301Z"
    }
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    def __init__(\n",
    "        self, \n",
    "        train_indices,\n",
    "        test_indices, \n",
    "        train_df, \n",
    "        featureMatrix,\n",
    "        labelMap\n",
    "    ):\n",
    "        self.train_indices = train_indices\n",
    "        self.test_indices = test_indices\n",
    "        \n",
    "        self.num_train_examples = len(train_indices)\n",
    "        self.num_test_examples = len(test_indices)\n",
    "        \n",
    "        self.dataframe = train_df\n",
    "        self.featureMatrix = featureMatrix\n",
    "        self.labelMap = labelMap\n",
    "        self.trainFeatureMatrix = featureMatrix[train_indices]\n",
    "        \n",
    "        num_labels = len(labelMap.items())\n",
    "        num_vocab_words = self.featureMatrix.shape[1]\n",
    "        \n",
    "        self.class_distribution = np.zeros( (num_labels) )\n",
    "        self.likelihood_probabilities = np.zeros((num_labels, num_vocab_words, 2))\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        for i in train_indices:\n",
    "            self.class_distribution[labelMap[self.dataframe[\"author\"][i]]] += 1\n",
    "            \n",
    "        for i in tqdm(self.train_indices):\n",
    "            class_label = self.labelMap[self.dataframe[\"author\"][i]]\n",
    "            text = self.dataframe[\"text\"][i]\n",
    "            words = set(re.findall(\"[a-z0-9]+\", text.lower()))\n",
    "            for word in words:\n",
    "                if word in stopwords:\n",
    "                    continue\n",
    "                self.likelihood_probabilities[class_label,wordIndex[word]][1] += 1\n",
    "        \n",
    "        for i in range(self.likelihood_probabilities.shape[0]):\n",
    "            for j in range(self.likelihood_probabilities.shape[1]):\n",
    "                self.likelihood_probabilities[i,j,0] = self.class_distribution[i] - self.likelihood_probabilities[i,j,1]\n",
    "                self.likelihood_probabilities[i,j,0] /= self.class_distribution[i]\n",
    "                self.likelihood_probabilities[i,j,1] /= self.class_distribution[i]\n",
    "        \n",
    "#         for i in range(len(self.class_distribution)):\n",
    "#             self.class_distribution[i] /= self.num_train_examples\n",
    "            \n",
    "#       Vectorize\n",
    "        self.class_distribution /= self.num_train_examples\n",
    "\n",
    "    \n",
    "    def apply_laplace_correction(self, alpha):\n",
    "        \n",
    "        self.class_distribution = np.zeros(self.class_distribution.shape)\n",
    "        self.likelihood_probabilities = np.zeros(self.likelihood_probabilities.shape)\n",
    "        \n",
    "        for i in train_indices:\n",
    "            self.class_distribution[labelMap[self.dataframe[\"author\"][i]]] += 1\n",
    "            \n",
    "        self.likelihood_probabilities = np.zeros((len(class_labels), self.featureMatrix.shape[1], 2))\n",
    "        for i in tqdm(self.train_indices):\n",
    "            class_label = self.labelMap[self.dataframe[\"author\"][i]]\n",
    "            text = self.dataframe[\"text\"][i]\n",
    "            words = set(re.findall(\"[a-z0-9]+\", text.lower()))\n",
    "            for word in words:\n",
    "                if word in stopwords:\n",
    "                    continue\n",
    "                self.likelihood_probabilities[class_label,wordIndex[word]][1] += 1\n",
    "           \n",
    "        for i in range(self.likelihood_probabilities.shape[0]):\n",
    "            for j in range(self.likelihood_probabilities.shape[1]):\n",
    "                \n",
    "                self.likelihood_probabilities[i,j,0] = self.class_distribution[i] - self.likelihood_probabilities[i,j,1]\n",
    "                \n",
    "                if self.likelihood_probabilities[i,j,0] == 0 or self.likelihood_probabilities[i,j,1] == 0 :\n",
    "                    self.likelihood_probabilities[i,j,0] = (self.likelihood_probabilities[i,j,0] + alpha) / (3*alpha + self.class_distribution[i])\n",
    "                    self.likelihood_probabilities[i,j,1] = (self.likelihood_probabilities[i,j,1] + alpha) / (3*alpha + self.class_distribution[i])\n",
    "                else:\n",
    "                    self.likelihood_probabilities[i,j,1] /= self.class_distribution[i]\n",
    "                    self.likelihood_probabilities[i,j,0] /= self.class_distribution[i]\n",
    "                 \n",
    "                \n",
    "#         for i in range(self.class_distribution.shape[0]):\n",
    "#             self.class_distribution[i] /= self.num_train_examples\n",
    "        \n",
    "#       Vectorize\n",
    "        self.class_distribution /= self.num_train_examples\n",
    "\n",
    "    def evaluate_example(self, feature_vector):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ------------\n",
    "        featureVector : (X1,X2,X3,.....Xn) [n = num_vocab_words]\n",
    "\n",
    "\n",
    "        Returns\n",
    "        ------------\n",
    "        The predicted label of the example\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        feature_vector = feature_vector.toarray()[0]\n",
    "        \n",
    "        best_class, best_probability = None, 0\n",
    "        \n",
    "        for class_name, class_num in self.labelMap.items():\n",
    "            \n",
    "            cur_probability = self.class_distribution[class_num]\n",
    "            \n",
    "            \n",
    "#             for j in range(feature_vector.shape[1]):\n",
    "#                 cur_probability *= self.likelihood_probabilities[class_num, j,feature_vector[0][j]]\n",
    "            \n",
    "            feature_vector_row_indices = [i for i in range(feature_vector.shape[0])]\n",
    "            vectorized = self.likelihood_probabilities[class_num, feature_vector_row_indices, feature_vector]\n",
    "            \n",
    "            cur_probability *= np.prod(vectorized)\n",
    "    \n",
    "            if best_class is None:\n",
    "                best_class  = class_name\n",
    "                best_probability = cur_probability\n",
    "            elif cur_probability > best_probability:\n",
    "                best_class  = class_name\n",
    "                best_probability = cur_probability\n",
    "        \n",
    "        return best_class\n",
    "\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Predict Accuracy of All test samples\n",
    "        \"\"\"\n",
    "        correctly_predicted = 0\n",
    "        \n",
    "        for j in tqdm(range(self.num_test_examples)):\n",
    "            if(self.evaluate_example(self.featureMatrix[self.test_indices[j]]) == self.dataframe[\"author\"][self.test_indices[j]]):\n",
    "                correctly_predicted += 1\n",
    "        \n",
    "        correctly_predicted /= self.num_test_examples\n",
    "        \n",
    "        self.accuracy = correctly_predicted * 100\n",
    "        \n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:51:40.392730Z",
     "start_time": "2021-10-18T16:51:40.380043Z"
    }
   },
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split_indices(num_examples, percentage_split = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:51:40.583518Z",
     "start_time": "2021-10-18T16:51:40.569316Z"
    }
   },
   "outputs": [],
   "source": [
    "NBClassifier = NaiveBayesClassifier(\n",
    "    train_indices, \n",
    "    test_indices, \n",
    "    train_df, \n",
    "    featureMatrix,\n",
    "    labelMap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:51:41.633039Z",
     "start_time": "2021-10-18T16:51:40.731502Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13705/13705 [00:00<00:00, 18586.13it/s]\n"
     ]
    }
   ],
   "source": [
    "NBClassifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:52:22.264809Z",
     "start_time": "2021-10-18T16:51:41.635008Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5874/5874 [00:40<00:00, 144.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58.324821246169556"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBClassifier.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:52:22.268610Z",
     "start_time": "2021-10-18T16:52:22.266870Z"
    }
   },
   "outputs": [],
   "source": [
    "# for alpha in [0.01,0.1,1,10,100]:\n",
    "#     NBClassifier.apply_laplace_correction(alpha)\n",
    "#     print(f\"{NBClassifier.test()} <== {alpha}\")\n",
    "\n",
    "# alpha  |   %accuracy\n",
    "# 0.01 ------ 83\n",
    "# 0.1 ------- 83\n",
    "# 1 --------- 77-79\n",
    "# 10 -------- 41\n",
    "# 100 ------- 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:52:23.331947Z",
     "start_time": "2021-10-18T16:52:22.270096Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13705/13705 [00:00<00:00, 17827.34it/s]\n"
     ]
    }
   ],
   "source": [
    "NBClassifier.apply_laplace_correction(alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T16:53:04.933464Z",
     "start_time": "2021-10-18T16:52:23.333580Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5874/5874 [00:41<00:00, 141.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.26012938372489"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBClassifier.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T17:13:47.742282Z",
     "start_time": "2021-10-18T17:13:47.725099Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"test_indices.json\",\"w\") as f:\n",
    "    f.write(json.dumps(test_indices, indent = 4))\n",
    "    \n",
    "with open(\"train_indices.json\",\"w\") as f:\n",
    "    f.write(json.dumps(train_indices, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
