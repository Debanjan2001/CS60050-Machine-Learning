{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:09.079387Z",
     "start_time": "2021-10-20T05:19:52.172048Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T17:02:12.155866Z",
     "start_time": "2021-10-12T17:02:11.908703Z"
    }
   },
   "source": [
    "### TRAINING: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:09.298860Z",
     "start_time": "2021-10-20T05:20:09.088261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19579x24951 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 250731 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the feature matrix\n",
    "featureMatrix = sp.load_npz(\"feature_matrix.npz\")\n",
    "\n",
    "num_examples, num_vocab_words = featureMatrix.shape\n",
    "featureMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:16.352378Z",
     "start_time": "2021-10-20T05:20:09.304503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:20.976804Z",
     "start_time": "2021-10-20T05:20:16.353589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EAP', 'HPL', 'MWS']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of authors\n",
    "class_labels = list(train_df[\"author\"].unique())\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:23.346159Z",
     "start_time": "2021-10-20T05:20:20.978672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EAP': 0, 'HPL': 1, 'MWS': 2}\n"
     ]
    }
   ],
   "source": [
    "# Generate a dictionary which maps name of author to an integer. Used in array indexing.\n",
    "labelMap = {}\n",
    "for idx, label in enumerate(class_labels):\n",
    "    labelMap[label] = idx\n",
    "print(labelMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:23.749185Z",
     "start_time": "2021-10-20T05:20:23.348061Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "# Read the dictionary from json file.\n",
    "with open(\"word_index.json\", \"r\") as file:\n",
    "    wordIndex = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:24.025190Z",
     "start_time": "2021-10-20T05:20:23.752022Z"
    }
   },
   "outputs": [],
   "source": [
    "# A helper function which randomly split the indices of feature matrix into train split and test split with 70-\n",
    "# 30 ratio.\n",
    "def train_test_split_indices(num_examples, percentage_split):\n",
    "    all_indices = [i for i in range(num_examples)]\n",
    "    random.shuffle(all_indices)\n",
    "    num_training_examples = int(num_examples * percentage_split / 100 )\n",
    "    num_test_examples = num_examples - num_training_examples\n",
    "    train_indices, test_indices = all_indices[:num_training_examples], all_indices[num_training_examples:]\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:24.876199Z",
     "start_time": "2021-10-20T05:20:24.031408Z"
    }
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    def __init__(\n",
    "        self, \n",
    "        train_indices,\n",
    "        test_indices, \n",
    "        train_df, \n",
    "        featureMatrix,\n",
    "        labelMap\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ------------\n",
    "        train_indices:\n",
    "        test_indices:\n",
    "        train_df:\n",
    "        featureMatrix: \n",
    "        labelMap: Dictionary which maps name of author to an integer. Used in array indexing.\n",
    "        \n",
    "        Returns\n",
    "        ------------\n",
    "        None\n",
    "        This is the constructor of our Naive Bayes Classifier.\n",
    "        \"\"\"\n",
    "        self.train_indices = train_indices\n",
    "        self.test_indices = test_indices\n",
    "        \n",
    "        self.num_train_examples = len(train_indices)\n",
    "        self.num_test_examples = len(test_indices)\n",
    "        \n",
    "        self.dataframe = train_df\n",
    "        self.featureMatrix = featureMatrix\n",
    "        self.labelMap = labelMap\n",
    "        self.trainFeatureMatrix = featureMatrix[train_indices]\n",
    "        \n",
    "        num_labels = len(labelMap.items())\n",
    "        num_vocab_words = self.featureMatrix.shape[1]\n",
    "        \n",
    "        self.class_distribution = np.zeros( (num_labels) )\n",
    "        self.likelihood_probabilities = np.zeros((num_labels, num_vocab_words, 2))\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ------------\n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        ------------\n",
    "        None\n",
    "        \n",
    "        This function trains the Classifier on the training examples and finds out the classs distributions, and \n",
    "        the different probabilities(Likelihood and Prior) which are used to calculate the posterior probability \n",
    "        for a test example. \n",
    "        \"\"\"\n",
    "        for i in train_indices:\n",
    "            self.class_distribution[labelMap[self.dataframe[\"author\"][i]]] += 1\n",
    "            \n",
    "        for i in tqdm(self.train_indices):\n",
    "            class_label = self.labelMap[self.dataframe[\"author\"][i]]\n",
    "            text = self.dataframe[\"text\"][i]\n",
    "            words = set(re.findall(\"[a-z0-9]+\", text.lower()))\n",
    "            for word in words:\n",
    "                if word in stopwords:\n",
    "                    continue\n",
    "                self.likelihood_probabilities[class_label,wordIndex[word]][1] += 1\n",
    "        \n",
    "        for i in range(self.likelihood_probabilities.shape[0]):\n",
    "            for j in range(self.likelihood_probabilities.shape[1]):\n",
    "                self.likelihood_probabilities[i,j,0] = self.class_distribution[i] - self.likelihood_probabilities[i,j,1]\n",
    "                self.likelihood_probabilities[i,j,0] /= self.class_distribution[i]\n",
    "                self.likelihood_probabilities[i,j,1] /= self.class_distribution[i]\n",
    "        \n",
    "        self.class_distribution /= self.num_train_examples\n",
    "\n",
    "    \n",
    "    def apply_laplace_correction(self, alpha):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ------------\n",
    "        alpha: A constant used in Laplace correction.\n",
    "        \n",
    "        Returns\n",
    "        ------------\n",
    "        None\n",
    "        \n",
    "        This function trains the Classifier on the training examples and finds out the classs distributions, and \n",
    "        the different probabilities(Likelihood and Prior) which are used to calculate the posterior probability \n",
    "        for a test example. It applies laplace correction to avoid zero probabilities.\n",
    "        If probability is x/N, then after applying Laplace correction it becomes (x + alpha)/(N + k*alpha)\n",
    "        \"\"\"\n",
    "        self.class_distribution = np.zeros(self.class_distribution.shape)\n",
    "        self.likelihood_probabilities = np.zeros(self.likelihood_probabilities.shape)\n",
    "        \n",
    "        for i in train_indices:\n",
    "            self.class_distribution[labelMap[self.dataframe[\"author\"][i]]] += 1\n",
    "            \n",
    "        self.likelihood_probabilities = np.zeros((len(class_labels), self.featureMatrix.shape[1], 2))\n",
    "        for i in tqdm(self.train_indices):\n",
    "            class_label = self.labelMap[self.dataframe[\"author\"][i]]\n",
    "            text = self.dataframe[\"text\"][i]\n",
    "            words = set(re.findall(\"[a-z0-9]+\", text.lower()))\n",
    "            for word in words:\n",
    "                if word in stopwords:\n",
    "                    continue\n",
    "                self.likelihood_probabilities[class_label,wordIndex[word]][1] += 1\n",
    "           \n",
    "        for i in range(self.likelihood_probabilities.shape[0]):\n",
    "            for j in range(self.likelihood_probabilities.shape[1]):\n",
    "                \n",
    "                self.likelihood_probabilities[i,j,0] = self.class_distribution[i] - self.likelihood_probabilities[i,j,1]\n",
    "                \n",
    "                if self.likelihood_probabilities[i,j,0] == 0 or self.likelihood_probabilities[i,j,1] == 0 :\n",
    "                    self.likelihood_probabilities[i,j,0] = (self.likelihood_probabilities[i,j,0] + alpha) / (3*alpha + self.class_distribution[i])\n",
    "                    self.likelihood_probabilities[i,j,1] = (self.likelihood_probabilities[i,j,1] + alpha) / (3*alpha + self.class_distribution[i])\n",
    "                else:\n",
    "                    self.likelihood_probabilities[i,j,1] /= self.class_distribution[i]\n",
    "                    self.likelihood_probabilities[i,j,0] /= self.class_distribution[i]\n",
    "                    \n",
    "        self.class_distribution /= self.num_train_examples\n",
    "\n",
    "    def evaluate_example(self, feature_vector):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ------------\n",
    "        featureVector : (X1,X2,X3,.....Xn) [n = num_vocab_words]\n",
    "\n",
    "\n",
    "        Returns\n",
    "        ------------\n",
    "        The predicted label of the example\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        feature_vector = feature_vector.toarray()[0]\n",
    "        \n",
    "        best_class, best_probability = None, 0\n",
    "        \n",
    "        for class_name, class_num in self.labelMap.items():\n",
    "            \n",
    "            cur_probability = self.class_distribution[class_num]\n",
    "\n",
    "            \n",
    "            feature_vector_row_indices = [i for i in range(feature_vector.shape[0])]\n",
    "            vectorized = self.likelihood_probabilities[class_num, feature_vector_row_indices, feature_vector]\n",
    "            \n",
    "            cur_probability *= np.prod(vectorized)\n",
    "    \n",
    "            if best_class is None:\n",
    "                best_class  = class_name\n",
    "                best_probability = cur_probability\n",
    "            elif cur_probability > best_probability:\n",
    "                best_class  = class_name\n",
    "                best_probability = cur_probability\n",
    "        \n",
    "        return best_class\n",
    "\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Predict Accuracy of All test samples\n",
    "        \"\"\"\n",
    "        correctly_predicted = 0\n",
    "        results = []\n",
    "        \n",
    "        for j in tqdm(range(self.num_test_examples)):\n",
    "            predicted = self.evaluate_example(self.featureMatrix[self.test_indices[j]])\n",
    "            actual = self.dataframe[\"author\"][self.test_indices[j]]\n",
    "            if predicted == actual:\n",
    "                correctly_predicted += 1\n",
    "            results.append([actual, predicted])\n",
    "        \n",
    "        correctly_predicted /= self.num_test_examples\n",
    "        \n",
    "        self.accuracy = correctly_predicted\n",
    "        self.predictions = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy, Precision, Sensitivity(Recall) , Specificity,  F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:25.569867Z",
     "start_time": "2021-10-20T05:20:24.878356Z"
    }
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import math\n",
    "\n",
    "# The following are helper functions which help generate different metrics to evalutate the model.\n",
    "def get_confidence_interval(score, number_of_samples):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ------------\n",
    "    score: score of the metric we find to find out confidence interval of\n",
    "    number_of_samples: Number of samples\n",
    "    \n",
    "    Returns \n",
    "    ------------\n",
    "    Confidence interval\n",
    "    \"\"\"\n",
    "    CI_CONST = 1.96\n",
    "    confidence_interval_upper = score + CI_CONST * math.sqrt((score*(1-score))/number_of_samples)\n",
    "    confidence_interval_lower = score - CI_CONST * math.sqrt((score*(1-score))/number_of_samples)\n",
    "    return [confidence_interval_lower, confidence_interval_upper]\n",
    "\n",
    "def generate_statistics(predictions, class_labels, labelMap):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ------------\n",
    "    predictions : A list of list of the format [actual,predicted]\n",
    "    class_labels : List of possible outcomes\n",
    "    labelMap : Mapping of Outcome to integer\n",
    "    \n",
    "    Returns \n",
    "    ------------\n",
    "    precision, f-score, sensitivity, specificity\n",
    "    \"\"\"\n",
    "    \n",
    "    num_classes = len(class_labels)\n",
    "    \n",
    "    true_positive, true_negative, false_positive, false_negative = [0] * num_classes,  [0] * num_classes,  [0] * num_classes,  [0] * num_classes\n",
    "    \n",
    "    for [actual_label, predicted_label] in predictions:\n",
    "        \n",
    "        actual_label_id = labelMap[actual_label]\n",
    "        predicted_label_id = labelMap[predicted_label]\n",
    "        \n",
    "        if actual_label == predicted_label:\n",
    "            true_positive[actual_label_id] += 1\n",
    "            \n",
    "            for label_id in range(num_classes):\n",
    "                if actual_label_id != label_id:\n",
    "                    true_negative[label_id] += 1\n",
    "        else: \n",
    "            false_positive[predicted_label_id] += 1\n",
    "            false_negative[actual_label_id] += 1\n",
    "            \n",
    "    \n",
    "    micro_precision = sum(true_positive) / ( sum(true_positive) + sum(false_positive) )\n",
    "    micro_sensitivity = sum(true_positive) / ( sum(true_positive) + sum(false_negative) )\n",
    "    micro_specificity = sum(true_negative) / ( sum(true_negative) + sum(false_positive) )\n",
    "    micro_f_score = (2 * micro_precision * micro_sensitivity) / (micro_precision + micro_sensitivity)\n",
    "    \n",
    "    \n",
    "    classwise_precision = [ true_positive[i] / (true_positive[i] + false_positive[i])  for i in range(num_classes)] \n",
    "    classwise_sensitivity = [ true_positive[i] / (true_positive[i] + false_negative[i])  for i in range(num_classes)]\n",
    "    classwise_specificity = [ true_negative[i] / (true_negative[i] + false_positive[i])  for i in range(num_classes)]\n",
    "    \n",
    "    macro_precision = mean(classwise_precision)\n",
    "    macro_sensitivity = mean(classwise_sensitivity)\n",
    "    macro_specificity = mean(classwise_specificity)\n",
    "    macro_f_score = mean([(2*classwise_precision[i] * classwise_sensitivity[i]) / (classwise_precision[i] + classwise_sensitivity[i]) for i in range(num_classes)])\n",
    "    \n",
    "    number_of_samples = len(predictions)\n",
    "    macro_precision_ci = get_confidence_interval(macro_precision, number_of_samples)\n",
    "    macro_sensitivity_ci = get_confidence_interval(macro_sensitivity, number_of_samples)\n",
    "    macro_specificity_ci = get_confidence_interval(macro_specificity, number_of_samples)\n",
    "    macro_f_score_ci = get_confidence_interval(macro_f_score, number_of_samples)\n",
    "    \n",
    "    print(\"MICRO STATS\")\n",
    "    print(f\"Micro Precision = {micro_precision}\")\n",
    "    print(f\"Micro Sensitivity(Recall) = {micro_sensitivity}\")    \n",
    "    print(f\"Micro Specificity = {micro_specificity}\")    \n",
    "    print(f\"Micro F-Score = {micro_f_score}\")    \n",
    "    \n",
    "    print(\"\\n****************\\n\")\n",
    "    \n",
    "    print(\"MACRO STATS\")\n",
    "    print(f\"Macro Precision = {macro_precision}\")\n",
    "    print(f\"Macro Sensitivity(Recall) = {macro_sensitivity}\")    \n",
    "    print(f\"Macro Specificity = {macro_specificity}\")    \n",
    "    print(f\"Macro F-Score = {macro_f_score}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:26.031776Z",
     "start_time": "2021-10-20T05:20:25.579338Z"
    }
   },
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split_indices(num_examples, percentage_split = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:26.327559Z",
     "start_time": "2021-10-20T05:20:26.034480Z"
    }
   },
   "outputs": [],
   "source": [
    "NBClassifier = NaiveBayesClassifier(\n",
    "    train_indices, \n",
    "    test_indices, \n",
    "    train_df, \n",
    "    featureMatrix,\n",
    "    labelMap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training NB Classifier without Laplacian correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:20:27.424520Z",
     "start_time": "2021-10-20T05:20:26.333440Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13705/13705 [00:00<00:00, 19326.62it/s]\n"
     ]
    }
   ],
   "source": [
    "NBClassifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:21:16.525059Z",
     "start_time": "2021-10-20T05:20:27.426239Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5874/5874 [00:49<00:00, 119.65it/s]\n"
     ]
    }
   ],
   "source": [
    "NBClassifier.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:21:16.531148Z",
     "start_time": "2021-10-20T05:21:16.527227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5881852230166837"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBClassifier.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:21:17.060851Z",
     "start_time": "2021-10-20T05:21:16.533064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5755989508680747, 0.6007714951652928]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_samples = len(NBClassifier.predictions)\n",
    "confidence_interval = get_confidence_interval(NBClassifier.accuracy, number_of_samples)\n",
    "confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:21:17.241289Z",
     "start_time": "2021-10-20T05:21:17.066440Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICRO STATS\n",
      "Micro Precision = 0.5881852230166837\n",
      "Micro Sensitivity(Recall) = 0.5881852230166837\n",
      "Micro Specificity = 0.7407010397684639\n",
      "Micro F-Score = 0.5881852230166837\n",
      "\n",
      "****************\n",
      "\n",
      "MACRO STATS\n",
      "Macro Precision = 0.707326296762176\n",
      "Macro Sensitivity(Recall) = 0.5446870666401318\n",
      "Macro Specificity = 0.7581278620492882\n",
      "Macro F-Score = 0.5472638202615497\n"
     ]
    }
   ],
   "source": [
    "predictions = NBClassifier.predictions\n",
    "generate_statistics(predictions, class_labels, labelMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- For Micro Case, Precision, Accuracy, Fscore,Recall all should be same and we got it as well "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training NB Classifier with Laplacian correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:21:18.517700Z",
     "start_time": "2021-10-20T05:21:17.243489Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13705/13705 [00:00<00:00, 16763.13it/s]\n"
     ]
    }
   ],
   "source": [
    "NBClassifier.apply_laplace_correction(alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:22:15.071873Z",
     "start_time": "2021-10-20T05:21:18.519844Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5874/5874 [00:56<00:00, 103.88it/s]\n"
     ]
    }
   ],
   "source": [
    "NBClassifier.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:22:15.075523Z",
     "start_time": "2021-10-20T05:22:15.073180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7892407218249915"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBClassifier.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:22:16.010256Z",
     "start_time": "2021-10-20T05:22:15.077570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICRO STATS\n",
      "Micro Precision = 0.7892407218249915\n",
      "Micro Sensitivity(Recall) = 0.7892407218249915\n",
      "Micro Specificity = 0.8822074215033302\n",
      "Micro F-Score = 0.7892407218249915\n",
      "\n",
      "****************\n",
      "\n",
      "MACRO STATS\n",
      "Macro Precision = 0.83412023119829\n",
      "Macro Sensitivity(Recall) = 0.7705625414597101\n",
      "Macro Specificity = 0.8788137016138269\n",
      "Macro F-Score = 0.7864081731595802\n"
     ]
    }
   ],
   "source": [
    "predictions = NBClassifier.predictions\n",
    "generate_statistics(predictions, class_labels, labelMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T05:22:16.662499Z",
     "start_time": "2021-10-20T05:22:16.014885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7788106525233968, 0.7996707911265862]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_samples = len(NBClassifier.predictions)\n",
    "confidence_interval = get_confidence_interval(NBClassifier.accuracy, number_of_samples)\n",
    "confidence_interval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
