{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:55.302705Z",
     "start_time": "2021-10-19T07:33:54.223862Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:55.450034Z",
     "start_time": "2021-10-19T07:33:55.305142Z"
    }
   },
   "outputs": [],
   "source": [
    "featureMatrix = sp.load_npz(\"feature_matrix.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:55.483293Z",
     "start_time": "2021-10-19T07:33:55.459494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19579x24951 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 250731 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:55.959522Z",
     "start_time": "2021-10-19T07:33:55.485731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  453,  1286,  1636,  3702,  6102,  6862,  8189, 10730, 13337,\n",
       "        13640, 13875, 16003, 16564, 17069, 18513, 19478, 19625, 23225,\n",
       "        24168, 24416, 24641]),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing if generated matrix was okay or not\n",
    "np.where(featureMatrix.toarray()[0] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T17:02:12.155866Z",
     "start_time": "2021-10-12T17:02:11.908703Z"
    }
   },
   "source": [
    "#### The code above was a test to check if everything seems fine after loading the featureMatrix from disk. Looks good to me\n",
    "\n",
    "### TRAINING: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:56.018779Z",
     "start_time": "2021-10-19T07:33:55.962003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:56.042403Z",
     "start_time": "2021-10-19T07:33:56.020517Z"
    }
   },
   "outputs": [],
   "source": [
    "num_examples, num_vocab_words = featureMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:56.123381Z",
     "start_time": "2021-10-19T07:33:56.048829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EAP', 'HPL', 'MWS']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = list(train_df[\"author\"].unique())\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:56.188467Z",
     "start_time": "2021-10-19T07:33:56.125746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EAP': 0, 'HPL': 1, 'MWS': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelMap = {}\n",
    "for idx, label in enumerate(class_labels):\n",
    "    labelMap[label] = idx\n",
    "labelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:56.255746Z",
     "start_time": "2021-10-19T07:33:56.190080Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split_indices(num_examples, percentage_split):\n",
    "    all_indices = [i for i in range(num_examples)]\n",
    "    random.shuffle(all_indices)\n",
    "    num_training_examples = int(num_examples * percentage_split / 100 )\n",
    "    num_test_examples = num_examples - num_training_examples\n",
    "    train_indices, test_indices = all_indices[:num_training_examples], all_indices[num_training_examples:]\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:56.323114Z",
     "start_time": "2021-10-19T07:33:56.257586Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:56.442101Z",
     "start_time": "2021-10-19T07:33:56.324745Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"word_index.json\", \"r\") as file:\n",
    "    wordIndex = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:56.548130Z",
     "start_time": "2021-10-19T07:33:56.444560Z"
    }
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    def __init__(\n",
    "        self, \n",
    "        train_indices,\n",
    "        test_indices, \n",
    "        train_df, \n",
    "        featureMatrix,\n",
    "        labelMap\n",
    "    ):\n",
    "        self.train_indices = train_indices\n",
    "        self.test_indices = test_indices\n",
    "        \n",
    "        self.num_train_examples = len(train_indices)\n",
    "        self.num_test_examples = len(test_indices)\n",
    "        \n",
    "        self.dataframe = train_df\n",
    "        self.featureMatrix = featureMatrix\n",
    "        self.labelMap = labelMap\n",
    "        self.trainFeatureMatrix = featureMatrix[train_indices]\n",
    "        \n",
    "        num_labels = len(labelMap.items())\n",
    "        num_vocab_words = self.featureMatrix.shape[1]\n",
    "        \n",
    "        self.class_distribution = np.zeros( (num_labels) )\n",
    "        self.likelihood_probabilities = np.zeros((num_labels, num_vocab_words, 2))\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        for i in train_indices:\n",
    "            self.class_distribution[labelMap[self.dataframe[\"author\"][i]]] += 1\n",
    "            \n",
    "        for i in tqdm(self.train_indices):\n",
    "            class_label = self.labelMap[self.dataframe[\"author\"][i]]\n",
    "            text = self.dataframe[\"text\"][i]\n",
    "            words = set(re.findall(\"[a-z0-9]+\", text.lower()))\n",
    "            for word in words:\n",
    "                if word in stopwords:\n",
    "                    continue\n",
    "                self.likelihood_probabilities[class_label,wordIndex[word]][1] += 1\n",
    "        \n",
    "        for i in range(self.likelihood_probabilities.shape[0]):\n",
    "            for j in range(self.likelihood_probabilities.shape[1]):\n",
    "                self.likelihood_probabilities[i,j,0] = self.class_distribution[i] - self.likelihood_probabilities[i,j,1]\n",
    "                self.likelihood_probabilities[i,j,0] /= self.class_distribution[i]\n",
    "                self.likelihood_probabilities[i,j,1] /= self.class_distribution[i]\n",
    "        \n",
    "#         for i in range(len(self.class_distribution)):\n",
    "#             self.class_distribution[i] /= self.num_train_examples\n",
    "            \n",
    "#       Vectorize\n",
    "        self.class_distribution /= self.num_train_examples\n",
    "\n",
    "    \n",
    "    def apply_laplace_correction(self, alpha):\n",
    "        \n",
    "        self.class_distribution = np.zeros(self.class_distribution.shape)\n",
    "        self.likelihood_probabilities = np.zeros(self.likelihood_probabilities.shape)\n",
    "        \n",
    "        for i in train_indices:\n",
    "            self.class_distribution[labelMap[self.dataframe[\"author\"][i]]] += 1\n",
    "            \n",
    "        self.likelihood_probabilities = np.zeros((len(class_labels), self.featureMatrix.shape[1], 2))\n",
    "        for i in tqdm(self.train_indices):\n",
    "            class_label = self.labelMap[self.dataframe[\"author\"][i]]\n",
    "            text = self.dataframe[\"text\"][i]\n",
    "            words = set(re.findall(\"[a-z0-9]+\", text.lower()))\n",
    "            for word in words:\n",
    "                if word in stopwords:\n",
    "                    continue\n",
    "                self.likelihood_probabilities[class_label,wordIndex[word]][1] += 1\n",
    "           \n",
    "        for i in range(self.likelihood_probabilities.shape[0]):\n",
    "            for j in range(self.likelihood_probabilities.shape[1]):\n",
    "                \n",
    "                self.likelihood_probabilities[i,j,0] = self.class_distribution[i] - self.likelihood_probabilities[i,j,1]\n",
    "                \n",
    "                if self.likelihood_probabilities[i,j,0] == 0 or self.likelihood_probabilities[i,j,1] == 0 :\n",
    "                    self.likelihood_probabilities[i,j,0] = (self.likelihood_probabilities[i,j,0] + alpha) / (3*alpha + self.class_distribution[i])\n",
    "                    self.likelihood_probabilities[i,j,1] = (self.likelihood_probabilities[i,j,1] + alpha) / (3*alpha + self.class_distribution[i])\n",
    "                else:\n",
    "                    self.likelihood_probabilities[i,j,1] /= self.class_distribution[i]\n",
    "                    self.likelihood_probabilities[i,j,0] /= self.class_distribution[i]\n",
    "                 \n",
    "                \n",
    "#         for i in range(self.class_distribution.shape[0]):\n",
    "#             self.class_distribution[i] /= self.num_train_examples\n",
    "        \n",
    "#       Vectorize\n",
    "        self.class_distribution /= self.num_train_examples\n",
    "\n",
    "    def evaluate_example(self, feature_vector):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ------------\n",
    "        featureVector : (X1,X2,X3,.....Xn) [n = num_vocab_words]\n",
    "\n",
    "\n",
    "        Returns\n",
    "        ------------\n",
    "        The predicted label of the example\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        feature_vector = feature_vector.toarray()[0]\n",
    "        \n",
    "        best_class, best_probability = None, 0\n",
    "        \n",
    "        for class_name, class_num in self.labelMap.items():\n",
    "            \n",
    "            cur_probability = self.class_distribution[class_num]\n",
    "            \n",
    "            \n",
    "#             for j in range(feature_vector.shape[1]):\n",
    "#                 cur_probability *= self.likelihood_probabilities[class_num, j,feature_vector[0][j]]\n",
    "            \n",
    "            feature_vector_row_indices = [i for i in range(feature_vector.shape[0])]\n",
    "            vectorized = self.likelihood_probabilities[class_num, feature_vector_row_indices, feature_vector]\n",
    "            \n",
    "            cur_probability *= np.prod(vectorized)\n",
    "    \n",
    "            if best_class is None:\n",
    "                best_class  = class_name\n",
    "                best_probability = cur_probability\n",
    "            elif cur_probability > best_probability:\n",
    "                best_class  = class_name\n",
    "                best_probability = cur_probability\n",
    "        \n",
    "        return best_class\n",
    "\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Predict Accuracy of All test samples\n",
    "        \"\"\"\n",
    "        correctly_predicted = 0\n",
    "        results = []\n",
    "        \n",
    "        for j in tqdm(range(self.num_test_examples)):\n",
    "            predicted = self.evaluate_example(self.featureMatrix[self.test_indices[j]])\n",
    "            actual = self.dataframe[\"author\"][self.test_indices[j]]\n",
    "            if predicted == actual:\n",
    "                correctly_predicted += 1\n",
    "            results.append([actual, predicted])\n",
    "        \n",
    "        correctly_predicted /= self.num_test_examples\n",
    "        \n",
    "        self.accuracy = correctly_predicted\n",
    "        self.predictions = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:56.992229Z",
     "start_time": "2021-10-19T07:33:56.549998Z"
    }
   },
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split_indices(num_examples, percentage_split = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:57.063146Z",
     "start_time": "2021-10-19T07:33:56.995111Z"
    }
   },
   "outputs": [],
   "source": [
    "NBClassifier = NaiveBayesClassifier(\n",
    "    train_indices, \n",
    "    test_indices, \n",
    "    train_df, \n",
    "    featureMatrix,\n",
    "    labelMap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:33:58.150181Z",
     "start_time": "2021-10-19T07:33:57.068742Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13705/13705 [00:00<00:00, 17118.57it/s]\n"
     ]
    }
   ],
   "source": [
    "NBClassifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:34:42.818754Z",
     "start_time": "2021-10-19T07:33:58.151539Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5874/5874 [00:39<00:00, 149.69it/s]\n"
     ]
    }
   ],
   "source": [
    "NBClassifier.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy, Precision, Sensitivity(Recall) , Specificity,  F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:34:42.831772Z",
     "start_time": "2021-10-19T07:34:42.821562Z"
    }
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import math\n",
    "\n",
    "def get_confidence_interval(score, number_of_samples):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ------------\n",
    "    score: score of the metric we find to find out confidence interval of\n",
    "    number_of_samples: Number of samples\n",
    "    \n",
    "    Returns \n",
    "    ------------\n",
    "    Confidence interval\n",
    "    \"\"\"\n",
    "    CI_CONST = 1.96\n",
    "    confidence_interval_upper = score + CI_CONST * math.sqrt((score*(1-score))/number_of_samples)\n",
    "    confidence_interval_lower = score - CI_CONST * math.sqrt((score*(1-score))/number_of_samples)\n",
    "    return [confidence_interval_lower, confidence_interval_upper]\n",
    "\n",
    "def generate_statistics(predictions, class_labels, labelMap):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ------------\n",
    "    predictions : A list of list of the format [actual,predicted]\n",
    "    class_labels : List of possible outcomes\n",
    "    labelMap : Mapping of Outcome to integer\n",
    "    \n",
    "    Returns \n",
    "    ------------\n",
    "    precision, f-score, sensitivity, specificity\n",
    "    \"\"\"\n",
    "    \n",
    "    num_classes = len(class_labels)\n",
    "    \n",
    "    true_positive, true_negative, false_positive, false_negative = [0] * num_classes,  [0] * num_classes,  [0] * num_classes,  [0] * num_classes\n",
    "#     print(true_positive, true_negative, false_positive, false_negative)\n",
    "    \n",
    "    for [actual_label, predicted_label] in predictions:\n",
    "        \n",
    "        actual_label_id = labelMap[actual_label]\n",
    "        predicted_label_id = labelMap[predicted_label]\n",
    "        \n",
    "        if actual_label == predicted_label:\n",
    "            true_positive[actual_label_id] += 1\n",
    "            \n",
    "            for label_id in range(num_classes):\n",
    "                if actual_label_id != label_id:\n",
    "                    true_negative[label_id] += 1\n",
    "        else: \n",
    "            false_positive[predicted_label_id] += 1\n",
    "            false_negative[actual_label_id] += 1\n",
    "            \n",
    "    \n",
    "    micro_precision = sum(true_positive) / ( sum(true_positive) + sum(false_positive) )\n",
    "    micro_sensitivity = sum(true_positive) / ( sum(true_positive) + sum(false_negative) )\n",
    "    micro_specificity = sum(true_negative) / ( sum(true_negative) + sum(false_positive) )\n",
    "    micro_f_score = (2 * micro_precision * micro_sensitivity) / (micro_precision + micro_sensitivity)\n",
    "    \n",
    "    \n",
    "    classwise_precision = [ true_positive[i] / (true_positive[i] + false_positive[i])  for i in range(num_classes)] \n",
    "    classwise_sensitivity = [ true_positive[i] / (true_positive[i] + false_negative[i])  for i in range(num_classes)]\n",
    "    classwise_specificity = [ true_negative[i] / (true_negative[i] + false_positive[i])  for i in range(num_classes)]\n",
    "    \n",
    "    macro_precision = mean(classwise_precision)\n",
    "    macro_sensitivity = mean(classwise_sensitivity)\n",
    "    macro_specificity = mean(classwise_specificity)\n",
    "    macro_f_score = mean([(2*classwise_precision[i] * classwise_sensitivity[i]) / (classwise_precision[i] + classwise_sensitivity[i]) for i in range(num_classes)])\n",
    "    \n",
    "    number_of_samples = len(predictions)\n",
    "    macro_precision_ci = get_confidence_interval(macro_precision, number_of_samples)\n",
    "    macro_sensitivity_ci = get_confidence_interval(macro_sensitivity, number_of_samples)\n",
    "    macro_specificity_ci = get_confidence_interval(macro_specificity, number_of_samples)\n",
    "    macro_f_score_ci = get_confidence_interval(macro_f_score, number_of_samples)\n",
    "#     print(true_positive, true_negative, false_positive, false_negative)\n",
    "#     print(number_of_samples)\n",
    "    \n",
    "    print(\"MICRO STATS\")\n",
    "    print(f\"Micro Precision = {micro_precision}\")\n",
    "    print(f\"Micro Sensitivity(Recall) = {micro_sensitivity}\")    \n",
    "    print(f\"Micro Specificity = {micro_specificity}\")    \n",
    "    print(f\"Micro F-Score = {micro_f_score}\")    \n",
    "    \n",
    "    \n",
    "    print(\"\\n****************\\n\")\n",
    "    print(\"MACRO STATS\")\n",
    "    print(f\"Macro Precision = {macro_precision}, {macro_precision_ci}\")\n",
    "    print(f\"Macro Sensitivity(Recall) = {macro_sensitivity}, {macro_sensitivity_ci}\")    \n",
    "    print(f\"Macro Specificity = {macro_specificity}, {macro_specificity_ci}\")    \n",
    "    print(f\"Macro F-Score = {macro_f_score}, {macro_f_score_ci}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:34:43.000469Z",
     "start_time": "2021-10-19T07:34:42.834687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5885257065032345"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBClassifier.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:34:43.074417Z",
     "start_time": "2021-10-19T07:34:43.006423Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICRO STATS\n",
      "Micro Precision = 0.5885257065032345\n",
      "Micro Sensitivity(Recall) = 0.5885257065032345\n",
      "Micro Specificity = 0.7409709570249705\n",
      "Micro F-Score = 0.5885257065032345\n",
      "\n",
      "****************\n",
      "\n",
      "MACRO STATS\n",
      "Macro Precision = 0.70153440127993, [0.6898323842128004, 0.7132364183470598]\n",
      "Macro Sensitivity(Recall) = 0.5455080416028929, [0.5327743953575621, 0.5582416878482237]\n",
      "Macro Specificity = 0.7572522567773409, [0.7462878033057502, 0.7682167102489316]\n",
      "Macro F-Score = 0.5488136239457543, [0.5360879869433933, 0.5615392609481152]\n"
     ]
    }
   ],
   "source": [
    "predictions = NBClassifier.predictions\n",
    "generate_statistics(predictions, class_labels, labelMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- For Micro Case, Precision, Accuracy, Fscore,Recall all should be same and we got it as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:34:43.142296Z",
     "start_time": "2021-10-19T07:34:43.077138Z"
    }
   },
   "outputs": [],
   "source": [
    "# for alpha in [0.01,0.1,1,10,100]:\n",
    "#     NBClassifier.apply_laplace_correction(alpha)\n",
    "#     print(f\"{NBClassifier.test()} <== {alpha}\")\n",
    "\n",
    "# alpha  |   %accuracy\n",
    "# 0.01 ------ 83\n",
    "# 0.1 ------- 83\n",
    "# 1 --------- 77-79\n",
    "# 10 -------- 41\n",
    "# 100 ------- 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:34:44.310382Z",
     "start_time": "2021-10-19T07:34:43.144364Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13705/13705 [00:00<00:00, 18532.94it/s]\n"
     ]
    }
   ],
   "source": [
    "NBClassifier.apply_laplace_correction(alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:35:29.393949Z",
     "start_time": "2021-10-19T07:34:44.311915Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5874/5874 [00:41<00:00, 142.50it/s]\n"
     ]
    }
   ],
   "source": [
    "NBClassifier.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:35:29.398423Z",
     "start_time": "2021-10-19T07:35:29.395737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.783792986040177"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBClassifier.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:35:29.567353Z",
     "start_time": "2021-10-19T07:35:29.399553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICRO STATS\n",
      "Micro Precision = 0.783792986040177\n",
      "Micro Sensitivity(Recall) = 0.783792986040177\n",
      "Micro Specificity = 0.8787936629127696\n",
      "Micro F-Score = 0.783792986040177\n",
      "\n",
      "****************\n",
      "\n",
      "MACRO STATS\n",
      "Macro Precision = 0.8310914420531165, [0.8215098134613498, 0.8406730706448832]\n",
      "Macro Sensitivity(Recall) = 0.7633631898637615, [0.7524940329518034, 0.7742323467757196]\n",
      "Macro Specificity = 0.8751469128281495, [0.8666935555336789, 0.8836002701226201]\n",
      "Macro F-Score = 0.7798771438366304, [0.7692813190989893, 0.7904729685742715]\n"
     ]
    }
   ],
   "source": [
    "predictions = NBClassifier.predictions\n",
    "generate_statistics(predictions, class_labels, labelMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:35:29.636284Z",
     "start_time": "2021-10-19T07:35:29.569302Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Cheating for future reference\n",
    "# with open(\"test_indices.json\",\"w\") as f:\n",
    "#     f.write(json.dumps(test_indices, indent = 4))\n",
    "    \n",
    "# with open(\"train_indices.json\",\"w\") as f:\n",
    "#     f.write(json.dumps(train_indices, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T07:35:29.704317Z",
     "start_time": "2021-10-19T07:35:29.638145Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(\"test_indices.json\", \"r\") as file:\n",
    "#     tind = json.load(file)\n",
    "# tind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
